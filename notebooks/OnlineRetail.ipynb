{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c339cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/31 16:37:08 WARN Utils: Your hostname, codespaces-66f68e resolves to a loopback address: 127.0.0.1; using 10.0.1.77 instead (on interface eth0)\n",
      "24/07/31 16:37:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/31 16:37:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity| InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "|   536365|     NULL|WHITE HANGING HEA...|     6.0|12/1/10 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|     6.0|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|     NULL|CREAM CUPID HEART...|     8.0|12/1/10 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|     NULL|KNITTED UNION FLA...|     6.0|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|     NULL|RED WOOLLY HOTTIE...|     6.0|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|     2.0|12/1/10 8:26|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|     6.0|12/1/10 8:26|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|     6.0|12/1/10 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|     6.0|12/1/10 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|    32.0|12/1/10 8:34|     1.69|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/31 16:37:21 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"Data Ingestion\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"InvoiceNo\", IntegerType(), nullable=False),\n",
    "    StructField(\"StockCode\", IntegerType(), nullable=False),\n",
    "    StructField(\"Description\", StringType(), nullable=False),\n",
    "    StructField(\"Quantity\", DoubleType(), nullable=False),\n",
    "    StructField(\"InvoiceDate\", StringType(), nullable=False),\n",
    "    StructField(\"UnitPrice\", DoubleType(), nullable=False),\n",
    "    StructField(\"CustomerID\", IntegerType(), nullable=False),\n",
    "    StructField(\"Country\", StringType(), nullable=False)\n",
    "])\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .schema(schema)\\\n",
    "    .load(\"/workspaces/DataEngineering/Csvs/online_retail.csv\")\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2c95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "#Delete if OutputCsv found already\n",
    "file_path = \"/workspaces/DataEngineering/OutputCsv/Country.csv\"\n",
    "shutil.rmtree(file_path)\n",
    "#Create Partition Csv for each country\n",
    "df.write.partitionBy(\"Country\").csv(f\"{file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af18d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Schema\n",
    "schema1 = StructType([\n",
    "    StructField(\"InvoiceNo\", IntegerType(), nullable=False),\n",
    "    StructField(\"StockCode\", IntegerType(), nullable=False),\n",
    "    StructField(\"Description\", StringType(), nullable=False),\n",
    "    StructField(\"Quantity\", DoubleType(), nullable=False),\n",
    "    StructField(\"InvoiceDate\", StringType(), nullable=False),\n",
    "    StructField(\"UnitPrice\", DoubleType(), nullable=False),\n",
    "    StructField(\"CustomerID\", IntegerType(), nullable=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5fa9ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------+---------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|  InvoiceDate|UnitPrice|CustomerID|\n",
      "+---------+---------+--------------------+--------+-------------+---------+----------+\n",
      "|   563031|    21932|SCANDINAVIAN PAIS...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    23209|LUNCH BAG VINTAGE...|     1.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    22384|LUNCH BAG PINK PO...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    20727|LUNCH BAG  BLACK ...|     1.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    22383|LUNCH BAG SUKI DE...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    23208|LUNCH BAG VINTAGE...|     1.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    20725|LUNCH BAG RED RET...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    20728| LUNCH BAG CARS BLUE|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    23207|LUNCH BAG ALPHABE...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|     NULL|SMALL MARSHMALLOW...|     2.0|8/11/11 14:38|     0.42|     13263|\n",
      "|   563031|     NULL|SMALL DOLLY MIX D...|     2.0|8/11/11 14:38|     0.42|     13263|\n",
      "|   563031|     NULL|SMALL CHOCOLATES ...|     2.0|8/11/11 14:38|     0.42|     13263|\n",
      "|   563031|     NULL|BISCUITS SMALL BO...|     1.0|8/11/11 14:38|     0.42|     13263|\n",
      "|   563031|    21218|RED SPOTTY BISCUI...|     1.0|8/11/11 14:38|     3.75|     13263|\n",
      "|   563031|    23301|GARDENERS KNEELIN...|     1.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|    23300|GARDENERS KNEELIN...|     1.0|8/11/11 14:38|     1.65|     13263|\n",
      "|   563031|     NULL|WHITE HANGING HEA...|     1.0|8/11/11 14:38|     2.95|     13263|\n",
      "|   563031|    23136|IVORY WIRE SWEETH...|     1.0|8/11/11 14:38|     3.75|     13263|\n",
      "|   563031|    23152|IVORY SWEETHEART ...|     1.0|8/11/11 14:38|     3.75|     13263|\n",
      "|   563031|    23321|SMALL WHITE HEART...|     2.0|8/11/11 14:38|     1.65|     13263|\n",
      "+---------+---------+--------------------+--------+-------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get All the data according to country name\n",
    "\n",
    "import os\n",
    "\n",
    "country = \"United Kingdom\"\n",
    "\n",
    "# Directory containing the files\n",
    "directory_path = f\"{file_path}/Country={country}\"\n",
    "\n",
    "# List all files in the directory that end with .csv\n",
    "csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "\n",
    "#Create single dataframe for mentioned country\n",
    "for file in csv_files:\n",
    "    tempDf = spark.read.schema(schema1).csv(f\"{directory_path}/{file}\", inferSchema=True)\n",
    "\n",
    "tempDf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e686c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top 5 buyer in the Country\n",
    "#Most expensive item in Country\n",
    "#Least expensive item in the Country\n",
    "#Average money spent by each buyer(remove null & negative outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b971f3",
   "metadata": {},
   "source": [
    "Get top 5 buyer in the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76538351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values in the dataset\n",
    "tempDf = tempDf.dropna(subset=[\"Quantity\", \"UnitPrice\", \"CustomerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a90823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get temp table\n",
    "tableName = \"TempTable\"\n",
    "tempDf.createOrReplaceTempView(tableName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6512bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerID|        TotalPrice|\n",
      "+----------+------------------+\n",
      "|     18102|129120.06999999996|\n",
      "|     17450|119534.68999999994|\n",
      "|     14096| 57120.91000000003|\n",
      "|     17511| 35551.64999999998|\n",
      "|     16684| 32770.05999999999|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tempSql = spark.sql(f\"SELECT CustomerID, SUM(Quantity*UnitPrice) AS TotalPrice FROM {tableName} GROUP BY CustomerID ORDER BY TotalPrice DESC LIMIT 5\")\n",
    "tempSql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c9844",
   "metadata": {},
   "source": [
    "Most expensive item in the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb8236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|Description|UnitPrice|\n",
      "+-----------+---------+\n",
      "|     Manual|  3155.95|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempSql = spark.sql(f\"SELECT Description, UnitPrice FROM {tableName} ORDER BY UnitPrice DESC LIMIT 1\")\n",
    "tempSql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715340c",
   "metadata": {},
   "source": [
    "Least expensive item in the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87697590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|         Description|UnitPrice|\n",
      "+--------------------+---------+\n",
      "|HANGING METAL HEA...|      0.0|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempSql = spark.sql(f\"SELECT Description, UnitPrice FROM {tableName} ORDER BY UnitPrice ASC LIMIT 1\")\n",
    "tempSql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5d122",
   "metadata": {},
   "source": [
    "Average money spent by each buyer(remove null/0 & negative outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c26fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove negative UnitPrice and Quantity\n",
    "\n",
    "tempSql = tempDf.filter((tempDf.UnitPrice >= 0) & (tempDf.Quantity >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e510ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerID|     AvgMoneySpent|\n",
      "+----------+------------------+\n",
      "|     15727| 12.89504424778761|\n",
      "|     16503|19.914117647058823|\n",
      "|     17389|246.46129032258062|\n",
      "|     12940| 8.507669902912621|\n",
      "|     17679| 66.40366666666668|\n",
      "|     16574|16.122857142857136|\n",
      "|     16861|             25.74|\n",
      "|     17420|23.035555555555554|\n",
      "|     15957|10.211666666666664|\n",
      "|     13623| 7.021000000000001|\n",
      "|     17172|          19.57875|\n",
      "|     18161|18.700666666666667|\n",
      "|     14514|19.183529411764706|\n",
      "|     16500|23.586000000000002|\n",
      "|     18221|14.841176470588236|\n",
      "|     15738|27.739649122807016|\n",
      "|     15296|  18.1955294117647|\n",
      "|     14837|15.194666666666668|\n",
      "|     14420|12.862333333333334|\n",
      "|     14997| 21.42777777777778|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempSql = spark.sql(f\"SELECT CustomerID, AVG(Quantity*UnitPrice) AS AvgMoneySpent FROM {tableName} GROUP BY CustomerID\")\n",
    "tempSql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203449c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
